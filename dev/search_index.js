var documenterSearchIndex = {"docs":
[{"location":"#KeemenaPreprocessing","page":"Home","title":"KeemenaPreprocessing","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for KeemenaPreprocessing.","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"#KeemenaPreprocessing.PreprocessBundle","page":"Home","title":"KeemenaPreprocessing.PreprocessBundle","text":"PreprocessBundle{IdT,OffsetT,ExtraT}\n\nIdT    : unsigned integer type for token ids (e.g. UInt32)\nOffsetT   : integer type for offsets  (e.g. Int or UInt32)\nExtraT : payload supplied by downstream packages (Nothing by default)\n\n\n\n\n\n","category":"type"},{"location":"#KeemenaPreprocessing.PreprocessConfiguration-Tuple{}","page":"Home","title":"KeemenaPreprocessing.PreprocessConfiguration","text":"PreprocessConfiguration(; kwargs...) -> PreprocessConfiguration\n\nBuild a fully-typed, immutable configuration object that controls every step of preprocess_corpus.  All keyword arguments are optional; the defaults shown below reproduce the behaviour of a 'typical' English-language pipeline.\n\nIf you mistype a keyword, or supply an illegal value, the constructor throws an AssertionError or ArgumentError immediately—so your downstream workflow can never run with hidden mistakes.\n\n────────────────────────────────────────────────────────────────────────────── Cleaning options ──────────────── lowercase                 = true &nbsp;&nbsp;→ convert text to lowercase   strip_accents             = true &nbsp;&nbsp;→ remove Unicode accents/diacritics   remove_control_characters = true   remove_punctuation        = true   normalise_whitespace      = true &nbsp;&nbsp;→ collapse runs of ␠, \\t, \\n into one space  \n\n────────────────────────────────────────────────────────────────────────────── Tokenisation ──────────── tokenizer_name            = :whitespace \\| :unicode \\| callable\n\n:whitespace - split(str) on ASCII whitespace.  \n:unicode    - splits on Unicode word-break boundaries (UAX #29).  \nFunction    - any f(::AbstractString)::Vector{String} you supply (e.g. a SentencePiece processor).\n\npreserve_empty_tokens     = false - keep empty strings that may arise from consecutive delimiters.\n\n────────────────────────────────────────────────────────────────────────────── Vocabulary building ─────────────────── minimum_token_frequency   = 1   -> discard tokens with lower frequency special_tokens            = Dict(:unk => \"<UNK>\", :pad => \"<PAD>\")\n\nThe dictionary is copied internally, so later mutation will not affect existing configurations.\n\n────────────────────────────────────────────────────────────────────────────── Segmentation levels to record (booleans) ──────────────────────────────────────── record_character_offsets  = false   record_word_offsets       = true   record_sentence_offsets   = true   record_paragraph_offsets  = true   record_document_offsets   = true  \n\nThese flags request which offset tables should appear in the resulting PreprocessBundle.  After processing you can inspect bundle.levels_present[:sentence] etc. to see which ones were actually populated.\n\n────────────────────────────────────────────────────────────────────────────── Examples ────────\n\nMinimal default config\n\ncfg = PreprocessConfiguration()\n\n#custom Unicode tokenizer and higher frequency cut-off\n\ncfg = PreprocessConfiguration(tokenizer_name          = :unicode,\n                              minimum_token_frequency = 5,\n                              lowercase               = false)\n                              \n#plug-in your own callable tokenizer (passing a function)\n\nunicode_tokenizer(s) = collect(eachmatch(r\"\\b\\p{L}[\\p{L}\\p{Mn}\\p{Pc}\\p{Nd}]*\b\", s)) .|> string\n\ncfg = PreprocessConfiguration(tokenizer_name = unicode_tokenizer,\n                              remove_punctuation = false)\n                              \n#you can pass cfg straight to preprocess_corpus:\n\nbundle = preprocess_corpus(text_files; config = cfg, save_to = \"bundle.jld2\")\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaPreprocessing.with_extras!-Union{Tuple{OffsetT}, Tuple{IdT}, Tuple{PreprocessBundle{IdT, OffsetT}, Any}} where {IdT, OffsetT}","page":"Home","title":"KeemenaPreprocessing.with_extras!","text":"with_extras!(bundle, new_extras; setlevel = nothing) -> new_bundle\n\nReturn a new PreprocessBundle sharing the same corpus & vocab but carrying new_extras.  If setlevel is provided it toggles the corresponding levels_present flag to true.\n\n\n\n\n\n","category":"method"}]
}
